#' Parametric nonlinear mixed effects model (NLME) approach: When true data are generated by the logistic model, the parametric NLME procedure is performed under the (missepcified) arctangent model .
#'
#' @param n number of sample size.
#' @param model a character string for a nonlinear model: \code{"logist"} or \code{"arctan"}.
#' @param dat a data frame of the generated data set.
#' @param num.boot number of bootsrap replicates.
#' @param time.length number of data points at which predictors are required for each individual longitudinal trajectory. This time point for graphs to be plotted.
#' @param num.grid number of data points at which predictors are required for each individual longitudinal trajectory.
#' @param true.theta1 a true parameter for \code{theta1}, which determines steepness of the logistic function, see \code{logistft()}.
#' @param true.theta3 a true parameter for \code{theta3}, which determines the maximum  (asymptote) of the logistic function, see \code{logistft()}.
#' @param para1 an initial parameter for \code{gam1}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para2 an initial intercept parameter for the inflection point \code{gam2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para3 an initial (p-1)-length of coefficient vector of subject specific covariates for the inflection point \code{gam2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para4 an initial parameter for \code{gam3}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para5 an initial vertical shift parameter for \code{gam4}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param eps.sd a true scale parameter of the within-subject error term in the longitudinal model.
#' @param dist a character string for the distribution of within-subject error term in the longitudinal model. Default is \code{"normal"}.
#'
#'
#'
#'
#' @return A list of
#'
#'        \item{est.beta}{the (p-1)-length of estimated coefficient vector of subjec-specific covariates in the log-normal model for inflection points.}
#'        \item{est.beta0}{estimated intercept of the log-normal model for inflection points.}
#'        \item{est.str.beta}{the (p-1)-length of estimated standard errors of the coefficient vector of subject-specific covariates in the log-normal model for inflection points.}
#'        \item{est.str.beta0}{estimated standard errors of the intercept of the log-normal model for inflection points.}
#'        \item{cp.lower.beta0}{estimated lower bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.upper.beta0}{estimated upper bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.lower.beta}{estimated lower bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{cp.upper.beta}{estimated upper bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{est.rand.ef}{estimated random effects in the log normal model for the inflection points.}
#'        \item{est.logT}{the n-length of the estimated inflection points vector, where each element is the individual estimated inflection point.}
#'        \item{true.logT}{the n-length of the true inflection points vector, where each element is the true individual inflection point.}
#'        \item{new.pred.data}{a time.length x 5 x n array of data set to generate boostrap estimates, which includes ID, log scaled ages, subject specfici covariates, true longitudinal trajectories and estimated longitudinal trajectories for each subject.}
#'        \item{true.first.deriv}{a time.length x n array of the first derivatives of the true longitudinal trajectories, where each column is the first derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{true.second.deriv}{a time.length x n array of the second derivatives of the true longitudinal trajectories, where each column is the second derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.first.deriv}{a time.length x n array of the estiamted first derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.second.deriv}{a time.length x n array of the estiamted second derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{boot.est.logT}{a n x num.boot array of the bootstrap estimated inflection points, where each row is a num.boot-length of boostrap estimates of the inflection point for each subject.}
#'        \item{ind.sd}{the n-length of the estimated boostrap standard deviations, where each element is the estimated standard deviation of the bootstrap estimates for each subject (each row of \code{boot.est.logT}).}
#'        \item{cp.boot}{a n x 2 array of the 95\% bootstrap confidence intervals, where each row has the lower bound and the upper bound of the 95\% confidence interval for the individual inflection point (i.e., 25th and 97.5th percentiles of the increasing ordered boostrap estimates for each row of \code{boot.est.logT}).}
#'
#'
#'
#'
#' @export
#'
#' @examples
#'
#' library(HDChangePoint)
#'
#'
#' ## Specify parameters to generate true data
#' n=80;
#' model="logist";
#' p=2;
#' bb0=0.5;
#' bb=0.1;
#' x.sd=0.3;
#' v1=5;
#' v2=7;
#' dist="normal";
#' eps.sd=0.05;
#' u.sd=0.05;
#'
#' ## Specify parameters for the parametric NLME procedure
#'
#' num.boot=1000;
#' true.theta1=6;
#' true.theta3=1;
#' time.length=20;
#' eps.sd=0.05;
#' dist="normal";
#' para1=2.5;
#' para2=3.5;
#' para3=0;
#' para4=3;
#' para5=1;
#'
#' ## generate data with seed number
#'
#' set.seed(22)
#' outdat<-mydata(n=n, model=model, p=p, bb0=bb0, bb=bb, x.sd=x.sd, v1=v1, v2=v2, dist=dist, eps.sd=eps.sd, u.sd=u.sd)
#'
#' ## Do parametric NLME estimation
#' results<-main.arctan.missp.nlme(n=n, model=model,  dat=outdat, num.boot=num.boot, time.length=time.length,
#'                                 true.theta1=true.theta1, true.theta3=true.theta3, para1=para1, para2=para2,
#'                                 para3=para3, para4=para4, para5=para5,  eps.sd=eps.sd, dist=dist)
#'
#'
#'

main.arctan.missp.nlme<-function(n=80, model="logist",  dat=outdat, num.boot=1000, time.length=20,
                                 true.theta1=6, true.theta3=1,  para1=1, para2=3.5, para3=0, para4=3, para5=1,  eps.sd=0.05, dist="normal"){



  ################################################################
  ## data structure constructed by each subject:  List format  ###
  ## include subject i, covariate log age,                     ###
  ##         true nonlinear function omega, error term         ###
  ##         true inflection points, true beta,                ###
  ##         true covariate W associated with inflection pts   ###
  ################################################################


  tms.dat<-vector("list", n)


  for(id in 1:n){

    sub.dat<-dat[dat$subj.id==id, ]
    ll<-dim(sub.dat)[1]

    subj<-sub.dat$subj.id
    true.z<-sub.dat$true_z
    W.cov<-sub.dat$cov.W
    gender<-sub.dat$sex

    if (dist=="normal"){
      eps<-rnorm(ll,0,eps.sd)
    }


    logS<-sub.dat$xx
    tr.z<-unique(sub.dat$true_z)

    #omega<-w(logS, tr.z, model)
    omega<-sub.dat$omega
    tms<-omega+eps

    tms.dat[[id]]<-cbind(subj,tms, omega, logS, W.cov, gender, eps,  true.z)  # true.t,eps,


  }


  ## create data.frame from list type of data
  gendat<-do.call("rbind.data.frame", tms.dat)

  ## Create grouped Data
  newgrdata<-groupedData(tms~logS|subj, data=gendat, order.groups=FALSE)



  #################################################################################################################################################
  ## Fit nonlinear mixed model using nlme() in NLME package to estimate fixed effects and random effects
  ## in longitudinal model: true data are generated by logistic model
  ## tms: longitudinal response vector for a subject i and jth visit.
  ## logistf: fitted nonlinear model.
  ## gam1, gam3, and gam4: fixed effect
  ## gam2: log transformed inflection points, which is modeled by linear relationship with
  ##         subject specific covariate W.cov, containig fixed effect beta and random effects u
  ##
  ## logS: main covariate in the logitudinal model
  ## model: tms ~logistf(theta1, theta2,  logS)
  ## fixed: two sided linear model in the form of f1~x1, where f1: names of parameters, x1: covariates in the ##linear relationship with f1
  ##       eg. theat1 ~1
  ## random: two sided formula in the form of r1~x1, where r1: names of parameters, x1 specifies the random effects model for the parameter r1
  ## groups: ~g1 or ~g1/g2../gQ, specify the partitions of the data over which the random effects vary
  ## start: list of initial estimates for the fixed effects and random effects
  ## method: "REML" or "ML", modle is fit by maximizing the restricted log liklihood or log-likelihood.
  ## verbose: TRUE means information on the evoluation of the interative algorithm is printed. Default is FALSE.
  ###################################################################################################################################################


  tms.nlme<-nlme(tms~arctanf(gam1, gam2, gam3, gam4, logS), fixed=list(gam1~1, gam2~1+W.cov, gam3~1, gam4~1),
                 random=gam2~1|subj,
                 data=newgrdata, groups=~subj, start=list(fixed=c(para1, para2, para3, para4, para5)), method="ML", verbose=FALSE)

  #############################################
  ### logLike, AIC #
  #############################################
  tms.logLik<-summary(tms.nlme)$logLik
  tms.AIC<-summary(tms.nlme)$AIC

  #############################################
  ### estimates of fixed effect: theta1, beta #
  #############################################

  est.gam1<-summary(tms.nlme)$tTable[,"Value"]["gam1"]
  est.gam3<-summary(tms.nlme)$tTable[,"Value"]["gam3"]
  est.gam4<-summary(tms.nlme)$tTable[,"Value"]["gam4"]
  est.beta<-summary(tms.nlme)$tTable[,"Value"]["gam2.W.cov"]
  est.beta0<-summary(tms.nlme)$tTable[,"Value"]["gam2.(Intercept)"]

  #####################################
  ## standard errors of fixed effects #
  #####################################


  est.str.gam1<-summary(tms.nlme)$tTable[,"Std.Error"]["gam1"]
  est.str.gam3<-summary(tms.nlme)$tTable[,"Std.Error"]["gam3"]
  est.str.gam4<-summary(tms.nlme)$tTable[,"Std.Error"]["gam4"]
  est.str.beta<-summary(tms.nlme)$tTable[,"Std.Error"]["gam2.W.cov"]
  est.str.beta0<-summary(tms.nlme)$tTable[,"Std.Error"]["gam2.(Intercept)"]


  ##########################
  ##  coverage probability #
  ##########################
  cp.fixed<-intervals(tms.nlme, level=0.95, which=c("fixed"))

  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.gam1<- cp.fixed$fixed["gam1","lower"]
  cp.upper.gam1<- cp.fixed$fixed["gam1","upper"]

  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta0<- cp.fixed$fixed["gam2.(Intercept)","lower"]
  cp.upper.beta0<- cp.fixed$fixed["gam2.(Intercept)","upper"]

  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta<- cp.fixed$fixed["gam2.W.cov","lower"]
  cp.upper.beta<- cp.fixed$fixed["gam2.W.cov","upper"]

  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.gam3<-cp.fixed$fixed["gam3","lower"]
  cp.upper.gam3<-cp.fixed$fixed["gam3","upper"]


  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.gam4<-cp.fixed$fixed["gam4","lower"]
  cp.upper.gam4<-cp.fixed$fixed["gam4","upper"]


  #####################
  ##  scale parameter #
  #####################

  ## within-individual
  sig.eps<-tms.nlme$sigma


  ###############################################################
  ## Extract Random effects with augmented data from groupedData#
  ###############################################################
  augmented.dat<-random.effects(tms.nlme, augFrame=T, data=newgrdata);
  est.rand.ef<-augmented.dat[,"gam2.(Intercept)"];


  ##################################################
  ## estimate inflection points (random effects)  ##
  ## estimate bias for inflection points          ##
  ##################################################

  est.logT<-est.beta0+est.beta*augmented.dat[,"W.cov"]+est.rand.ef  # estimated logT
  true.logT<-augmented.dat[,"true.z"]


  #####################################################################################################
  ### predict(): popoulation prediction (random effects=0) at polulation level 0                    ###
  ###              within group predictions (use estimated random effects) at individual level 1    ###
  #####################################################################################################


  #########################################
  # predicted total motor score           #
  #########################################


  ## set the length of time points



  new.pred.data<- array(0, dim=c(time.length, 5, n),
                        dimnames=list(paste("visit",1:time.length,sep=""), c("pseudo.id","pseudo.logS","pseudo.wcov", "ture.pseudo.tms", "est.pseudo.tms"), paste("ID",1:n,sep="")));


  for (id in 1:n){

    #id<-1; rm(id)
    group<-newgrdata[newgrdata$subj==id, ]


    pseudo.xy<-approx(group[,"logS"], group[,"omega"], n=time.length)
    pseudo.logS<-pseudo.xy$x
    pseudo.omega<-pseudo.xy$y

    pseudo.id<-rep(id, time.length)
    pseudo.wcov<-rep(unique(group[,"W.cov"]), time.length)

    if (dist=="normal"){
      pseudo.err<-rnorm(time.length,0, eps.sd)

    }

    pseudo.tms<-pseudo.omega+pseudo.err

    new.dat<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms)


    pred.data<-data.frame(subj= new.dat[,"pseudo.id"], logS= new.dat[,"pseudo.logS"],
                          W.cov=new.dat[ ,"pseudo.wcov"])

    ## predictions for tms  based on newd
    pred.traj<-predict(tms.nlme, pred.data, level=1)
    new.pred.data[,,id]<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms, pred.traj)

  }



  boot.est.logT<-array(0, dim=c(n, num.boot),
                       dimnames=list(paste("id",1:n,sep=""),paste("boot",1:num.boot,sep=""))
  )

  for(b in 1:num.boot){


    boot.pred.data<-vector("list", n)



    for(id in 1:n){

      ind.pred.data<-new.pred.data[,,id]
      boot.size<-dim(ind.pred.data)[[1]]
      err<-ind.pred.data[, "ture.pseudo.tms"]-ind.pred.data[, "est.pseudo.tms"]
      err.boot<-sample(err, size=boot.size, replace=TRUE)
      boot.tms<-ind.pred.data[, "est.pseudo.tms"]+err.boot
      boot.pred.data[[id]]<-cbind(ind.pred.data, boot.tms)

    }

    boot.data<-do.call("rbind.data.frame", boot.pred.data)

    boot.tms.nlme<-nlme(boot.tms~arctanf(gam1, gam2, gam3, gam4, pseudo.logS), fixed=list(gam1~1, gam2~1+pseudo.wcov, gam3~1, gam4~1),
                        random=gam2~1|pseudo.id,
                        data=boot.data, groups=~pseudo.id, start=list(fixed=c(para1, para2, para3, para4, para5)), method="ML", verbose=FALSE)


    boot.est.beta<-summary(boot.tms.nlme)$tTable[,"Value"]["gam2.pseudo.wcov"]
    boot.est.beta0<-summary(boot.tms.nlme)$tTable[,"Value"]["gam2.(Intercept)"]


    boot.augmented.dat<-random.effects(boot.tms.nlme, augFrame=T, data=boot.data)
    boot.est.rand.ef<-boot.augmented.dat[,"gam2.(Intercept)"]

    boot.est.logT[,b]<-boot.est.beta0+boot.est.beta*boot.augmented.dat[,"pseudo.wcov"]+boot.est.rand.ef  # estimated logT


  }



  ind.sd<-rep(100,n);
  cp.boot<-array(0, dim=c(n, 2),
                 dimnames=list(paste("id",1:n,sep=""),c("95% lower", "95% upper"))
  )


  for (id in 1:n){
    ind.boot<-boot.est.logT[id, ]
    ind.sd[id]<-sd(ind.boot)
    order.ind.boot<-sort(ind.boot)
    cp.boot[id,]<-quantile(order.ind.boot, prob=c(0.025, 0.975))

  }





  #########################################################
  # First and Second Derivative of Longitudinal Responses #
  #########################################################


  true.first.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  true.second.deriv<-array(0, dim=c(time.length,n),
                           dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))

  est.first.deriv<-array(0, dim=c(time.length,n),
                         dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  est.second.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))


  for (id in 1:n){
    #id<-5; rm(id)
    sub.logs<-new.pred.data[,"pseudo.logS",id]


    true.first.deriv[,id]<-logist_first_deriv_ft(true.theta1, true.logT[id], true.theta3,  sub.logs)
    true.second.deriv[,id]<-logist_second_deriv_ft(true.theta1,  true.logT[id], true.theta3,  sub.logs)


    est.first.deriv[,id]<-arctan_first_deriv_ft(est.gam1,  est.logT[id], est.gam3,  sub.logs)
    est.second.deriv[,id]<-arctan_second_deriv_ft(est.gam1,  est.logT[id], est.gam3,  sub.logs)


  }



  return(list(  new.pred.data= new.pred.data,

                est.beta=est.beta, est.beta0=est.beta0, #estimates

                est.str.beta=est.str.beta, est.str.beta0=est.str.beta0,#standard errors

                cp.lower.beta0=cp.lower.beta0, cp.upper.beta0=cp.upper.beta0, cp.lower.beta=cp.lower.beta, cp.upper.beta=cp.upper.beta, #coverage prob


                #newgrdata=newgrdata,
                sig.eps=sig.eps,
                est.rand.ef=est.rand.ef,
                est.logT=est.logT, true.logT=true.logT,

                ## bias of derivatives
                true.first.deriv=true.first.deriv,  true.second.deriv= true.second.deriv,  est.first.deriv= est.first.deriv, est.second.deriv=est.second.deriv,
                ## bootstrap estimation

                boot.est.logT=boot.est.logT,  ind.sd=ind.sd, cp.boot=cp.boot

  ))

}


