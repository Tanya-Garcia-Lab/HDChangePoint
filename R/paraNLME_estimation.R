#' Parametric nonlinear mixed effects model (NLME) approach: When true data are generated by the logistic model, the parametric NLME procedure is performed under the correct logistic model.
#'
#' @param n  number of sample size.
#' @param model a character string for a nonlinear model: \code{"logist"} or \code{"arctan"}.
#' @param dat a data frame of the generated data set.
#' @param num.boot number of bootsrap replicates.
#' @param true.theta1 a true parameter for \code{theta1}, which determines steepness of the logistic function, see \code{logistft()}.
#' @param true.theta3 a true parameter for \code{theta3}, which determines the maximum  (asymptote) of the logistic function, see \code{logistft()}.
#' @param time.length number of data points at which predictors are required for each individual longitudinal trajectory. This time point for graphs to be plotted.
#' @param eps.sd a true scale parameter of the within-subject error term in the longitudinal model.
#' @param dist a character string for the distribution of within-subject error term in the longitudinal model. Default is \code{"normal"}.
#' @param para1 an initial parameter for \code{theta1}, which is used in function \code{logistft()} for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para2 an initial intercept parameter for the inflection point \code{theta2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para3 an initial (p-1)-length of coefficient vector of subject-specific covariates for the inflection point \code{theta2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para4 an initial parameter for \code{theta3}, which is used in function \code{logistft()} for the parametric nonlinear mixed effects model (NLME) approach.
#'
#'
#'
#' @return A list of
#'\itemize{
#'        \item{est.theta1}{estimated fixed effect parameter for \code{theta1}, see \code{logistft()}.}
#'        \item{est.beta}{the (p-1)-length of estimated coefficient vector of subjec-specific covariates in the log-normal model for inflection points.}
#'        \item{est.beta0}{estimated intercept of the log-normal model for inflection points.}
#'        \item{est.theta3}{estimated fixed effect parameter for \code{theta3}, see \code{logistft()}.}
#'        \item{est.str.theta1}{estimated standard error of \code{theta1}.}
#'        \item{est.str.beta}{the (p-1)-length of estimated standard errors of the coefficient vector of subject-specific covariates in the log-normal model for inflection points.}
#'        \item{est.str.beta0}{estimated standard errors of the intercept of the log-normal model for inflection points.}
#'        \item{est.str.theta3}{estimated standard error of \code{theta3}.}
#'        \item{cp.lower.theta1}{estimated lower bound of the 95\% confidence interval for \code{theta1}.}
#'        \item{cp.upper.theta1}{estimated upper bound of the 95\% confidence interval for \code{theta1}.}
#'        \item{cp.lower.beta0}{estimated lower bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.upper.beta0}{estimated upper bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.lower.beta}{estimated lower bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{cp.upper.beta}{estimated upper bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{cp.lower.theta3}{estimated lower bound of the 95\% confidence interval for \code{theta3}.}
#'        \item{cp.upper.theta3}{estimated upper bound of the 95\% confidence interval for \code{theta3}.}
#'        \item{est.rand.ef}{estimated random effects in the log normal model for the inflection points.}
#'        \item{est.logT}{the n-length of the estimated inflection points vector, where each element is the individual estimated inflection point.}
#'        \item{true.logT}{the n-length of the true inflection points vector, where each element is the true individual inflection point.}
#'        \item{new.pred.data}{a time.length x 5 x n array of data set to generate boostrap estimates, which includes ID, log scaled ages, subject specfici covariates, true longitudinal trajectories and estimated longitudinal trajectories for each subject.}
#'        \item{true.first.deriv}{a time.lengthx n array of the first derivatives of the true longitudinal trajectories, where each column is the first derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{true.second.deriv}{a time.length x n array of the second derivatives of the true longitudinal trajectories, where each column is the second derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.first.deriv}{a time.length x n array of the estiamted first derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.second.deriv}{a time.length x n array of the estiamted second derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{boot.est.logT}{a n x num.boot array of the bootstrap estimated inflection points, where each row is a num.boot-length of boostrap estimates of the inflection point for each subject.}
#'        \item{ind.sd}{the n-length of the estimated boostrap standard deviations, where each element is the estimated standard deviation of the bootstrap estimates for each subject (each row of \code{boot.est.logT}).}
#'        \item{cp.boot}{a n x 2 array of the 95\% bootstrap confidence intervals, where each row has the lower bound and the upper bound of the 95\% confidence interval for the individual inflection point (i.e., 25th and 97.5th percentiles of the increasing ordered boostrap estimates for each row of \code{boot.est.logT}).}
#'}
#' @import nlme
#' @export
#'
#' @example man/examples/logist_nlme_examples.R


main.logist.nlme<-function(n=80, model="logist", dat=outdat, num.boot=1000,
                           true.theta1=1, true.theta3=6, time.length=20, eps.sd=0.05, dist="normal", para1=3.5, para2=0.1, para3=0.1, para4=1){ # alpha=-5
  
  
  ################################################################
  ## data structure constructed by each subject:  List format  ###
  ## include subject i, covariate log age,                     ###
  ##         true nonlinear function omega, error term         ###
  ##         true inflection points, true beta,                ###
  ##         true covariate W associated with inflection pts   ###
  ################################################################
  
  
  tms.dat<-vector("list", n)
  
  
  for(id in 1:n){
    
    sub.dat<-dat[dat$subj.id==id, ]
    ll<-dim(sub.dat)[1]
    
    subj<-sub.dat$subj.id
    true.z<-sub.dat$true_z
    W.cov<-sub.dat$cov.W
    gender<-sub.dat$sex
    
    if (dist=="normal"){
      eps<-rnorm(ll,0,eps.sd)
    }
    
    
    logS<-sub.dat$xx
    tr.z<-unique(sub.dat$true_z)
    
    #omega<-w(logS, tr.z, model)
    omega<-sub.dat$omega
    tms<-omega+eps
    
    tms.dat[[id]]<-cbind(subj,tms, omega, logS, W.cov, gender,  eps, true.z)  # true.t,eps,
    
    
  }
  
  
  ## create data.frame from list type of data
  gendat<-do.call("rbind.data.frame", tms.dat)
  
  ## Create grouped Data
  newgrdata<-groupedData(tms~logS|subj, data=gendat, order.groups=FALSE)
  
  #mean(unique(newgrdata$true.z))
  #################################################################################################################################################
  ## Fit nonlinear mixed model using nlme() in NLME package to estimate fixed effects and random effects
  ## in longitudinal model: true data are generated by logistic model
  ## tms: longitudinal response vector for a subject i and jth visit.
  ## logistf: fitted nonlinear model.
  ## theta1: fixed effect
  ## theta2: log transformed inflection points, which is modeled by linear relationship with
  ##         subject specific covariate W.cov, containig fixed effect beta and random effects u
  ##
  ## logS: main covariate in the logitudinal model
  ## model: tms ~logistf(theta1, theta2,  logS)
  ## fixed: two sided linear model in the form of f1~x1, where f1: names of parameters, x1: covariates in the ##linear relationship with f1
  ##       eg. theat1 ~1
  ## random: two sided formula in the form of r1~x1, where r1: names of parameters, x1 specifies the random effects model for the parameter r1
  ## groups: ~g1 or ~g1/g2../gQ, specify the partitions of the data over which the random effects vary
  ## start: list of initial estimates for the fixed effects and random effects
  ## method: "REML" or "ML", modle is fit by maximizing the restricted log liklihood or log-likelihood.
  ## verbose: TRUE means information on the evoluation of the interative algorithm is printed. Default is FALSE.
  ###################################################################################################################################################
  
  
  tms.nlme<-nlme(tms~logistft(theta1, theta2, theta3, logS), fixed=list(theta1~1, theta2~1+W.cov, theta3~1) , random=list(theta2~1),
                 data= newgrdata, groups=~subj,  start=list(fixed=c(para1,para2,para3,para4)), method="ML", verbose=FALSE)
  
  
  #############################################
  ### estimates of fixed effect: theta1, beta #
  #############################################
  
  est.theta1<-summary(tms.nlme)$tTable[,"Value"]["theta1"]
  est.beta<-summary(tms.nlme)$tTable[,"Value"]["theta2.W.cov"]
  est.beta0<-summary(tms.nlme)$tTable[,"Value"]["theta2.(Intercept)"]
  est.theta3<-summary(tms.nlme)$tTable[,"Value"]["theta3"]
  
  #####################################
  ## standard errors of fixed effects #
  #####################################
  
  est.str.theta1<-sqrt(tms.nlme$varFix["theta1","theta1"])
  est.str.beta<-sqrt(tms.nlme$varFix["theta2.W.cov","theta2.W.cov"])
  
  est.str.theta1<-summary(tms.nlme)$tTable[,"Std.Error"]["theta1"]
  est.str.beta<-summary(tms.nlme)$tTable[,"Std.Error"]["theta2.W.cov"]
  est.str.theta3<-summary(tms.nlme)$tTable[,"Std.Error"]["theta3"]
  est.str.beta0<-summary(tms.nlme)$tTable[,"Std.Error"]["theta2.(Intercept)"]
  
  
  ##########################
  ##  coverage probability #
  ##########################
  cp.fixed<-intervals(tms.nlme, level=0.95, which=c("fixed"))
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.theta1<- cp.fixed$fixed["theta1","lower"]
  cp.upper.theta1<- cp.fixed$fixed["theta1","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta0<- cp.fixed$fixed["theta2.(Intercept)","lower"]
  cp.upper.beta0<- cp.fixed$fixed["theta2.(Intercept)","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta<- cp.fixed$fixed["theta2.W.cov","lower"]
  cp.upper.beta<- cp.fixed$fixed["theta2.W.cov","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.theta3<-cp.fixed$fixed["theta3","lower"]
  cp.upper.theta3<-cp.fixed$fixed["theta3","upper"]
  
  
  #####################
  ##  scale parameter #
  #####################
  
  ## within-individual
  sig.eps<-tms.nlme$sigma
  
  
  ###############################################################
  ## Extract Random effects with augmented data from groupedData#
  ###############################################################
  augmented.dat<-random.effects(tms.nlme, augFrame=T, data=newgrdata)
  est.rand.ef<-augmented.dat[,"theta2.(Intercept)"]
  
  
  ##################################################
  ## estimate inflection points (random effects)  ##
  ## estimate bias for inflection points          ##
  ##################################################
  
  est.logT<-est.beta0+est.beta*augmented.dat[,"W.cov"]+est.rand.ef  # estimated logT
  true.logT<-augmented.dat[,"true.z"]
  
  #####################################################################################################
  ### predict(): popoulation prediction (random effects=0) at polulation level 0                    ###
  ###              within group predictions (use estimated random effects) at individual level 1    ###
  #####################################################################################################
  
  
  #########################################
  # predicted total motor score           #
  #########################################
  
  
  
  new.pred.data<- array(0, dim=c(time.length, 5, n),
                        dimnames=list(paste("visit",1:time.length,sep=""), c("pseudo.id","pseudo.logS","pseudo.wcov", "ture.pseudo.tms", "est.pseudo.tms"), paste("ID",1:n,sep="")));
  
  
  
  for (id in 1:n){
    
    group<-newgrdata[newgrdata$subj==id, ]
    
    
    pseudo.xy<-approx(group[,"logS"], group[,"omega"], n=time.length)
    pseudo.logS<-pseudo.xy$x
    pseudo.omega<-pseudo.xy$y
    
    pseudo.id<-rep(id, time.length)
    pseudo.wcov<-rep(unique(group[,"W.cov"]), time.length)
    
    if (dist=="normal"){
      pseudo.err<-rnorm(time.length,0, eps.sd)
      
    }
    
    pseudo.tms<-pseudo.omega+pseudo.err
    
    new.dat<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms)
    
    
    pred.data<-data.frame(subj= new.dat[,"pseudo.id"], logS= new.dat[,"pseudo.logS"],
                          W.cov=new.dat[ ,"pseudo.wcov"])
    
    ## predictions for tms  based on newd
    pred.traj<-predict(tms.nlme, pred.data, level=1)
    new.pred.data[,,id]<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms, pred.traj)
    
  }
  
  
  boot.est.logT<-array(0, dim=c(n, num.boot),
                       dimnames=list(paste("id",1:n,sep=""),paste("boot",1:num.boot,sep=""))
  )
  
  for(b in 1:num.boot){
    
    
    boot.pred.data<-vector("list", n)
    
    
    
    for(id in 1:n){
      
      ind.pred.data<-new.pred.data[,,id]
      boot.size<-dim(ind.pred.data)[[1]]
      err<-ind.pred.data[, "ture.pseudo.tms"]-ind.pred.data[, "est.pseudo.tms"]
      err.boot<-sample(err, size=boot.size, replace=TRUE)
      boot.tms<-ind.pred.data[, "est.pseudo.tms"]+err.boot
      boot.pred.data[[id]]<-cbind(ind.pred.data, boot.tms)
      
    }
    
    boot.data<-do.call("rbind.data.frame", boot.pred.data)
    boot.tms.nlme<-nlme(boot.tms~logistft(theta1, theta2, theta3,pseudo.logS), fixed=list(theta1~1, theta2~1+pseudo.wcov, theta3~1) , random=list(theta2~1),
                        data=boot.data, groups=~pseudo.id,  start=list(fixed=c(para1, para2,para3, para4)), method="ML", verbose=FALSE)
    
    boot.est.beta<-summary(boot.tms.nlme)$tTable[,"Value"]["theta2.pseudo.wcov"]
    boot.est.beta0<-summary(boot.tms.nlme)$tTable[,"Value"]["theta2.(Intercept)"]
    
    
    boot.augmented.dat<-random.effects(boot.tms.nlme, augFrame=T, data=boot.data)
    boot.est.rand.ef<-boot.augmented.dat[,"theta2.(Intercept)"]
    
    boot.est.logT[,b]<-boot.est.beta0+boot.est.beta*boot.augmented.dat[,"pseudo.wcov"]+boot.est.rand.ef  # estimated logT
    
  }
  
  
  
  ind.sd<-rep(100,n);
  cp.boot<-array(0, dim=c(n, 2),
                 dimnames=list(paste("id",1:n,sep=""),c("95% lower", "95% upper"))
  )
  
  
  for (id in 1:n){
    ind.boot<-boot.est.logT[id, ]
    ind.sd[id]<-sd(ind.boot)
    order.ind.boot<-sort(ind.boot)
    cp.boot[id,]<-quantile(order.ind.boot, prob=c(0.025, 0.975))
    
  }
  
  
  
  #########################################################
  # First and Second Derivative of Longitudinal Responses #
  #########################################################
  
  
  true.first.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  true.second.deriv<-array(0, dim=c(time.length,n),
                           dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  
  est.first.deriv<-array(0, dim=c(time.length,n),
                         dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  est.second.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  
  
  for (id in 1:n){
    
    sub.logs<-new.pred.data[,"pseudo.logS",id]
    
    
    true.first.deriv[,id]<-logist_first_deriv_ft(true.theta1, true.logT[id], true.theta3,  sub.logs)
    true.second.deriv[,id]<-logist_second_deriv_ft(true.theta1,  true.logT[id], true.theta3,  sub.logs)
    
    
    est.first.deriv[,id]<-logist_first_deriv_ft(est.theta1,  est.logT[id], est.theta3,  sub.logs)
    est.second.deriv[,id]<-logist_second_deriv_ft(est.theta1,  est.logT[id], est.theta3,  sub.logs)
    
    
  }
  
  
  
  return(list( new.pred.data=new.pred.data,
               est.theta1=est.theta1,
               est.beta=est.beta,est.beta0=est.beta0, est.theta3=est.theta3,  #estimates
               
               est.str.theta1=est.str.theta1,
               est.str.beta=est.str.beta,est.str.beta0=est.str.beta0, est.str.theta3=est.str.theta3,
               
               cp.lower.theta1=cp.lower.theta1, cp.upper.theta1=cp.upper.theta1,
               cp.lower.theta3=cp.lower.theta3, cp.upper.theta3=cp.upper.theta3,
               cp.lower.beta0=cp.lower.beta0, cp.upper.beta0=cp.upper.beta0, cp.lower.beta=cp.lower.beta, cp.upper.beta=cp.upper.beta, #coverage prob
               
               newgrdata=newgrdata,
               
               sig.eps=sig.eps,
               
               est.rand.ef=est.rand.ef,
               est.logT=est.logT, true.logT=true.logT,
               
               ## bias of derivatives
               true.first.deriv=true.first.deriv,  true.second.deriv= true.second.deriv,  est.first.deriv= est.first.deriv, est.second.deriv=est.second.deriv,
               ## bootstrap estimation
               boot.est.logT=boot.est.logT,  ind.sd=ind.sd, cp.boot=cp.boot
  ))
  
}

#' Parametric nonlinear mixed effects model (NLME) approach: When true data are generated by the arctangent model, the parametric NLME procedure is performed under the correct arctangent model.
#'
#' @param n number of sample size.
#' @param model a character string for a nonlinear model: \code{"logist"} or \code{"arctan"}.
#' @param dat a data frame of the generated data set.
#' @param num.boot number of bootsrap replicates.
#' @param time.length number of data points at which predictors are required for each individual longitudinal trajectory. This time point for graphs to be plotted.
#' @param true.gam1 a true scale parameter for \code{gam1} in the arctangent model, see \code{arctanf()}.
#' @param true.gam3 a true parameter for \code{gam3}, which determines steepness of the arctangent model, see \code{arctanf()}.
#' @param para1 an initial parameter for \code{gam1}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para2 an initial intercept parameter for the inflection point \code{gam2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para3 an initial (p-1)-length of coefficient vector of subject specific covariates for the inflection point \code{gam2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para4 an initial parameter for \code{gam3}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para5 an initial vertical shift parameter for \code{gam4}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param eps.sd a true scale parameter of the within-subject error term in the longitudinal model.
#' @param dist a character string for the distribution of within-subject error term in the longitudinal model. Default is \code{"normal"}.
#'
#'
#'
#'
#'
#' @return A list of
#'\itemize{
#'        \item{est.gam1}{estimated fixed effect parameter for \code{gam1} in the arctangent function, see \code{arctanf()}.}
#'        \item{est.beta}{the (p-1)-length of estimated coefficient vector of subjec-specific covariates in the log-normal model for inflection points.}
#'        \item{est.beta0}{estimated intercept of the log-normal model for inflection points.}
#'        \item{est.gam3}{estimated fixed effect parameter for \code{gam3} in the arctangent function, see \code{arctanf()}.}
#'        \item{est.gam4}{estimated fixed effect parameter for \code{gam4} in the arctangent function, see \code{arctanf()}.}
#'        \item{est.str.gam1}{estimated standard error of \code{gam1}.}
#'        \item{est.str.beta}{the (p-1)-length of estimated standard errors of the coefficient vector of subject-specific covariates in the log-normal model for inflection points.}
#'        \item{est.str.beta0}{estimated standard errors of the intercept of the log-normal model for inflection points.}
#'        \item{est.str.gam3}{estimated standard error of \code{gam3}.}
#'        \item{est.str.gam4}{estimated standard error of \code{gam4}.}
#'        \item{cp.lower.gam1}{estimated lower bound of the 95\% confidence interval for \code{gam1}.}
#'        \item{cp.upper.gam1}{estimated upper bound of the 95\% confidence interval for \code{gam1}.}
#'        \item{cp.lower.beta0}{estimated lower bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.upper.beta0}{estimated upper bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.lower.beta}{estimated lower bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{cp.upper.beta}{estimated upper bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{cp.lower.gam3}{estimated lower bound of the 95\% confidence interval for \code{gam3}.}
#'        \item{cp.upper.gam3}{estimated upper bound of the 95\% confidence interval for \code{gam3}.}
#'        \item{cp.lower.gam4}{estimated lower bound of the 95\% confidence interval for \code{gam4}.}
#'        \item{cp.upper.gam4}{estimated upper bound of the 95\% confidence interval for \code{gam4}.}
#'        \item{est.rand.ef}{estimated random effects in the log normal model for the inflection points.}
#'        \item{est.logT}{the n-length of the estimated inflection points vector, where each element is the individual estimated inflection point.}
#'        \item{true.logT}{the n-length of the true inflection points vector, where each element is the true individual inflection point.}
#'        \item{new.pred.data}{a time.length x 5 x n array of data set to generate boostrap estimates, which includes ID, log scaled ages, subject specfici covariates, true longitudinal trajectories and estimated longitudinal trajectories for each subject.}
#'        \item{true.first.deriv}{a time.length x n array of the first derivatives of the true longitudinal trajectories, where each column is the first derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{true.second.deriv}{a time.length x n array of the second derivatives of the true longitudinal trajectories, where each column is the second derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.first.deriv}{a time.length x n array of the estiamted first derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.second.deriv}{a time.length x n array of the estiamted second derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{boot.est.logT}{a n x num.boot array of the bootstrap estimated inflection points, where each row is a num.boot-length of boostrap estimates of the inflection point for each subject.}
#'        \item{ind.sd}{the n-length of the estimated boostrap standard deviations, where each element is the estimated standard deviation of the bootstrap estimates for each subject (each row of \code{boot.est.logT}).}
#'        \item{cp.boot}{a n x 2 array of the 95\% bootstrap confidence intervals, where each row has the lower bound and the upper bound of the 95\% confidence interval for the individual inflection point (i.e., 25th and 97.5th percentiles of the increasing ordered boostrap estimates for each row of \code{boot.est.logT}).}
#'}
#'
#'
#'
#' @import nlme
#' @export
#'
#' @example man/examples/arctan_nlme_examples.R
#'


main.arctan.nlme<-function(n=80, model="arctan", dat=outdat, num.boot=1000,  time.length=20, true.gam1=2.45/pi, true.gam3=pi/1.1, para1=0.8,  para2=0.2, para3=0.2, para4=2.8, para5=1.5,  eps.sd=0.05, dist="normal"){
  
  
  ################################################################
  ## data structure constructed by each subject:  List format  ###
  ## include subject i, covariate log age,                     ###
  ##         true nonlinear function omega, error term         ###
  ##         true inflection points, true beta,                ###
  ##         true covariate W associated with inflection pts   ###
  ################################################################
  
  
  
  tms.dat<-vector("list", n)
  
  
  for(id in 1:n){
    #id<-1;rm(id)
    sub.dat<-dat[dat$subj.id==id, ]
    ll<-dim(sub.dat)[1]
    
    subj<-sub.dat$subj.id
    true.z<-sub.dat$true_z
    W.cov<-sub.dat$cov.W
    gender<-sub.dat$sex
    
    if (dist=="normal"){
      eps<-rnorm(ll,0,eps.sd)
    }
    
    
    logS<-sub.dat$xx
    tr.z<-unique(sub.dat$true_z)
    
    #omega<-w(logS, tr.z, model)
    omega<-sub.dat$omega
    tms<-omega+eps #sub.dat$yy
    
    tms.dat[[id]]<-cbind(subj,tms, omega, logS, W.cov, gender,eps, true.z)  # true.t,
    
    
  }
  
  
  ## create data.frame from list type of data
  gendat<-do.call("rbind.data.frame", tms.dat)
  
  ## Create grouped Data
  newgrdata<-groupedData(tms~logS|subj, data=gendat, order.groups=FALSE)
  
  #mean(unique(newgrdata$true.z))
  #################################################################################################################################################
  ## Fit nonlinear mixed model using nlme() in NLME package to estimate fixed effects and random effects
  ## in longitudinal model: true data are generated by logistic model
  ## tms: longitudinal response vector for a subject i and jth visit.
  ## logistf: fitted nonlinear model.
  ## theta1: fixed effect
  ## theta2: log transformed inflection points, which is modeled by linear relationship with
  ##         subject specific covariate W.cov, containig fixed effect beta and random effects u
  ##
  ## logS: main covariate in the logitudinal model
  ## model: tms ~logistf(theta1, theta2,  logS)
  ## fixed: two sided linear model in the form of f1~x1, where f1: names of parameters, x1: covariates in the ##linear relationship with f1
  ##       eg. theat1 ~1
  ## random: two sided formula in the form of r1~x1, where r1: names of parameters, x1 specifies the random effects model for the parameter r1
  ## groups: ~g1 or ~g1/g2../gQ, specify the partitions of the data over which the random effects vary
  ## start: list of initial estimates for the fixed effects and random effects
  ## method: "REML" or "ML", modle is fit by maximizing the restricted log liklihood or log-likelihood.
  ## verbose: TRUE means information on the evoluation of the interative algorithm is printed. Default is FALSE.
  ###################################################################################################################################################
  
  #para1=0.8; para2=6.4; para3=0; para4=2.8; para5=1.5
  tms.nlme<-nlme(tms~arctanf(gam1, gam2, gam3, gam4,  logS), fixed=list(gam1~1, gam2~1+W.cov, gam3~1, gam4~1),
                 random=gam2~1|subj,
                 data=newgrdata, groups=~subj, start=list(fixed=c(para1,para2,para3,para4,para5)), method="ML", verbose=FALSE)
  
  
  #############################################
  ### logLike, AIC #
  #############################################
  tms.logLik<-summary(tms.nlme)$logLik
  tms.AIC<-summary(tms.nlme)$AIC
  
  #############################################
  ### estimates of fixed effect: theta1, beta #
  #############################################
  
  est.gam1<-summary(tms.nlme)$tTable[,"Value"]["gam1"]
  est.gam3<-summary(tms.nlme)$tTable[,"Value"]["gam3"]
  est.gam4<-summary(tms.nlme)$tTable[,"Value"]["gam4"]
  est.beta<-summary(tms.nlme)$tTable[,"Value"]["gam2.W.cov"]
  est.beta0<-summary(tms.nlme)$tTable[,"Value"]["gam2.(Intercept)"]
  
  #####################################
  ## standard errors of fixed effects #
  #####################################
  
  
  
  est.str.gam1<-summary(tms.nlme)$tTable[,"Std.Error"]["gam1"]
  est.str.gam3<-summary(tms.nlme)$tTable[,"Std.Error"]["gam3"]
  est.str.gam4<-summary(tms.nlme)$tTable[,"Std.Error"]["gam4"]
  est.str.beta<-summary(tms.nlme)$tTable[,"Std.Error"]["gam2.W.cov"]
  est.str.beta0<-summary(tms.nlme)$tTable[,"Std.Error"]["gam2.(Intercept)"]
  
  
  ##########################
  ##  coverage probability #
  ##########################
  cp.fixed<-intervals(tms.nlme, level=0.95, which=c("fixed"))
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.gam1<- cp.fixed$fixed["gam1","lower"]
  cp.upper.gam1<- cp.fixed$fixed["gam1","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta0<- cp.fixed$fixed["gam2.(Intercept)","lower"]
  cp.upper.beta0<- cp.fixed$fixed["gam2.(Intercept)","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta<- cp.fixed$fixed["gam2.W.cov","lower"]
  cp.upper.beta<- cp.fixed$fixed["gam2.W.cov","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.gam3<-cp.fixed$fixed["gam3","lower"]
  cp.upper.gam3<-cp.fixed$fixed["gam3","upper"]
  
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.gam4<-cp.fixed$fixed["gam4","lower"]
  cp.upper.gam4<-cp.fixed$fixed["gam4","upper"]
  
  
  #####################
  ##  scale parameter #
  #####################
  
  ## within-individual ##
  sig.eps<-tms.nlme$sigma
  
  
  
  ###############################################################
  ## Extract Random effects with augmented data from groupedData#
  ###############################################################
  augmented.dat<-random.effects(tms.nlme, augFrame=T, data=newgrdata);
  est.rand.ef<-augmented.dat[,"gam2.(Intercept)"];
  
  
  
  ##################################################
  ## estimate inflection points (random effects)  ##
  ## estimate bias for inflection points          ##
  ##################################################
  
  est.logT<-est.beta0+est.beta*augmented.dat[,"W.cov"]+est.rand.ef  # estimated logT
  true.logT<-augmented.dat[,"true.z"]
  
  
  
  
  #####################################################################################################
  ### predict(): popoulation prediction (random effects=0) at polulation level 0                    ###
  ###              within group predictions (use estimated random effects) at individual level 1    ###
  #####################################################################################################
  
  
  #########################################
  # predicted total motor score           #
  #########################################
  
  ## set the length of time points
  
  new.pred.data<- array(0, dim=c(time.length, 5, n),
                        dimnames=list(paste("visit",1:time.length,sep=""), c("pseudo.id","pseudo.logS","pseudo.wcov", "ture.pseudo.tms", "est.pseudo.tms"), paste("ID",1:n,sep="")));
  
  
  for (id in 1:n){
    
    #id<-1; rm(id)
    group<-newgrdata[newgrdata$subj==id, ]
    
    
    pseudo.xy<-approx(group[,"logS"], group[,"omega"], n=time.length)
    pseudo.logS<-pseudo.xy$x
    pseudo.omega<-pseudo.xy$y
    
    pseudo.id<-rep(id, time.length)
    pseudo.wcov<-rep(unique(group[,"W.cov"]), time.length)
    
    if (dist=="normal"){
      pseudo.err<-rnorm(time.length,0, eps.sd)
      
    }
    
    pseudo.tms<-pseudo.omega+pseudo.err
    
    new.dat<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms)
    
    
    pred.data<-data.frame(subj= new.dat[,"pseudo.id"], logS= new.dat[,"pseudo.logS"],
                          W.cov=new.dat[ ,"pseudo.wcov"])
    
    ## predictions for tms  based on newd
    pred.traj<-predict(tms.nlme, pred.data, level=1)
    new.pred.data[,,id]<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms, pred.traj)
    
  }
  
  
  
  boot.est.logT<-array(0, dim=c(n, num.boot),
                       dimnames=list(paste("id",1:n,sep=""),paste("boot",1:num.boot,sep=""))
  )
  
  for(b in 1:num.boot){
    
    
    boot.pred.data<-vector("list", n)
    
    
    
    for(id in 1:n){
      
      ind.pred.data<-new.pred.data[,,id]
      boot.size<-dim(ind.pred.data)[[1]]
      err<-ind.pred.data[, "ture.pseudo.tms"]-ind.pred.data[, "est.pseudo.tms"]
      err.boot<-sample(err, size=boot.size, replace=TRUE)
      boot.tms<-ind.pred.data[, "est.pseudo.tms"]+err.boot
      boot.pred.data[[id]]<-cbind(ind.pred.data, boot.tms)
      
    }
    
    boot.data<-do.call("rbind.data.frame", boot.pred.data)
    
    
    
    boot.tms.nlme<-nlme(boot.tms~arctanf(gam1, gam2, gam3, gam4, pseudo.logS), fixed=list(gam1~1, gam2~1+pseudo.wcov, gam3~1, gam4~1),
                        random=gam2~1|pseudo.id,
                        data=boot.data, groups=~pseudo.id, start=list(fixed=c(para1,para2,para3,para4,para5)), method="ML", verbose=FALSE)
    
    
    boot.est.beta<-summary(boot.tms.nlme)$tTable[,"Value"]["gam2.pseudo.wcov"]
    boot.est.beta0<-summary(boot.tms.nlme)$tTable[,"Value"]["gam2.(Intercept)"]
    
    
    boot.augmented.dat<-random.effects(boot.tms.nlme, augFrame=T, data=boot.data)
    boot.est.rand.ef<-boot.augmented.dat[,"gam2.(Intercept)"]
    
    boot.est.logT[,b]<-boot.est.beta0+boot.est.beta*boot.augmented.dat[,"pseudo.wcov"]+boot.est.rand.ef  # estimated logT
    
  }
  
  
  
  ind.sd<-rep(100,n);
  cp.boot<-array(0, dim=c(n, 2),
                 dimnames=list(paste("id",1:n,sep=""),c("95% lower", "95% upper"))
  )
  
  
  for (id in 1:n){
    ind.boot<-boot.est.logT[id, ]
    ind.sd[id]<-sd(ind.boot)
    order.ind.boot<-sort(ind.boot)
    cp.boot[id,]<-quantile(order.ind.boot, prob=c(0.025, 0.975))
    
  }
  
  
  
  #########################################################
  # First and Second Derivative of Longitudinal Responses #
  #########################################################
  
  
  true.first.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  true.second.deriv<-array(0, dim=c(time.length,n),
                           dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  
  est.first.deriv<-array(0, dim=c(time.length,n),
                         dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  est.second.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  
  
  for (id in 1:n){
    
    sub.logs<-new.pred.data[,"pseudo.logS",id]
    
    
    true.first.deriv[,id]<-arctan_first_deriv_ft(true.gam1, true.logT[id], true.gam3,  sub.logs)
    true.second.deriv[,id]<-arctan_second_deriv_ft(true.gam1,  true.logT[id], true.gam3,  sub.logs)
    
    
    est.first.deriv[,id]<-arctan_first_deriv_ft(est.gam1,  est.logT[id], est.gam3,  sub.logs)
    est.second.deriv[,id]<-arctan_second_deriv_ft(est.gam1,  est.logT[id], est.gam3,  sub.logs)
    
    
  }
  
  
  
  
  
  return(list(  new.pred.data=new.pred.data,
                est.gam1=est.gam1, est.gam3=est.gam3,est.gam4=est.gam4, est.beta=est.beta, est.beta0=est.beta0, #estimates
                
                est.str.gam1=est.str.gam1, est.str.gam3=est.str.gam3, est.str.gam4=est.str.gam4, est.str.beta=est.str.beta,est.str.beta0=est.str.beta0,#standard errors
                
                cp.lower.gam1=cp.lower.gam1, cp.upper.gam1=cp.upper.gam1, cp.lower.gam3=cp.lower.gam3, cp.upper.gam3=cp.upper.gam3,
                cp.lower.gam4=cp.lower.gam4, cp.upper.gam4=cp.upper.gam4,
                cp.lower.beta0=cp.lower.beta0, cp.upper.beta0=cp.upper.beta0, cp.lower.beta=cp.lower.beta, cp.upper.beta=cp.upper.beta, #coverage prob
                
                
                #newgrdata=newgrdata,
                sig.eps=sig.eps,
                
                est.rand.ef=est.rand.ef,
                est.logT=est.logT, true.logT=true.logT,                   ## bias of derivatives
                true.first.deriv=true.first.deriv,  true.second.deriv= true.second.deriv,  est.first.deriv= est.first.deriv, est.second.deriv=est.second.deriv,
                
                boot.est.logT=boot.est.logT,  ind.sd=ind.sd, cp.boot=cp.boot
  ))
  
}


#' Parametric nonlinear mixed effects model (NLME) approach: When true data are generated by the logistic model, the parametric NLME procedure is performed under the (missepcified) arctangent model.
#'
#' @param n number of sample size.
#' @param model a character string for a nonlinear model: \code{"logist"} or \code{"arctan"}.
#' @param dat a data frame of the generated data set.
#' @param num.boot number of bootsrap replicates.
#' @param time.length number of data points at which predictors are required for each individual longitudinal trajectory. This time point for graphs to be plotted.
#' @param true.theta1 a true parameter for \code{theta1}, which determines steepness of the logistic function, see \code{logistft()}.
#' @param true.theta3 a true parameter for \code{theta3}, which determines the maximum  (asymptote) of the logistic function, see \code{logistft()}.
#' @param para1 an initial parameter for \code{gam1}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para2 an initial intercept parameter for the inflection point \code{gam2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para3 an initial (p-1)-length of coefficient vector of subject specific covariates for the inflection point \code{gam2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para4 an initial parameter for \code{gam3}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para5 an initial vertical shift parameter for \code{gam4}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param eps.sd a true scale parameter of the within-subject error term in the longitudinal model.
#' @param dist a character string for the distribution of within-subject error term in the longitudinal model. Default is \code{"normal"}.
#'
#'
#'
#'
#' @return A list of
#' \itemize{
#'        \item{est.beta}{the (p-1)-length of estimated coefficient vector of subjec-specific covariates in the log-normal model for inflection points.}
#'        \item{est.beta0}{estimated intercept of the log-normal model for inflection points.}
#'        \item{est.str.beta}{the (p-1)-length of estimated standard errors of the coefficient vector of subject-specific covariates in the log-normal model for inflection points.}
#'        \item{est.str.beta0}{estimated standard errors of the intercept of the log-normal model for inflection points.}
#'        \item{cp.lower.beta0}{estimated lower bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.upper.beta0}{estimated upper bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.lower.beta}{estimated lower bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{cp.upper.beta}{estimated upper bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{est.rand.ef}{estimated random effects in the log normal model for the inflection points.}
#'        \item{est.logT}{the n-length of the estimated inflection points vector, where each element is the individual estimated inflection point.}
#'        \item{true.logT}{the n-length of the true inflection points vector, where each element is the true individual inflection point.}
#'        \item{new.pred.data}{a time.length x 5 x n array of data set to generate boostrap estimates, which includes ID, log scaled ages, subject specfici covariates, true longitudinal trajectories and estimated longitudinal trajectories for each subject.}
#'        \item{true.first.deriv}{a time.length x n array of the first derivatives of the true longitudinal trajectories, where each column is the first derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{true.second.deriv}{a time.length x n array of the second derivatives of the true longitudinal trajectories, where each column is the second derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.first.deriv}{a time.length x n array of the estiamted first derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.second.deriv}{a time.length x n array of the estiamted second derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{boot.est.logT}{a n x num.boot array of the bootstrap estimated inflection points, where each row is a num.boot-length of boostrap estimates of the inflection point for each subject.}
#'        \item{ind.sd}{the n-length of the estimated boostrap standard deviations, where each element is the estimated standard deviation of the bootstrap estimates for each subject (each row of \code{boot.est.logT}).}
#'        \item{cp.boot}{a n x 2 array of the 95\% bootstrap confidence intervals, where each row has the lower bound and the upper bound of the 95\% confidence interval for the individual inflection point (i.e., 25th and 97.5th percentiles of the increasing ordered boostrap estimates for each row of \code{boot.est.logT}).}
#'}
#'
#'
#' @import nlme
#' @export
#'
#' @example man/examples/missp_arctan_nlme_examples.R



main.arctan.missp.nlme<-function(n=80, model="logist",  dat=outdat, num.boot=1000, time.length=20,
                                 true.theta1=6, true.theta3=1,  para1=1, para2=3.5, para3=0, para4=3, para5=1,  eps.sd=0.05, dist="normal"){
  
  
  
  ################################################################
  ## data structure constructed by each subject:  List format  ###
  ## include subject i, covariate log age,                     ###
  ##         true nonlinear function omega, error term         ###
  ##         true inflection points, true beta,                ###
  ##         true covariate W associated with inflection pts   ###
  ################################################################
  
  
  tms.dat<-vector("list", n)
  
  
  for(id in 1:n){
    
    sub.dat<-dat[dat$subj.id==id, ]
    ll<-dim(sub.dat)[1]
    
    subj<-sub.dat$subj.id
    true.z<-sub.dat$true_z
    W.cov<-sub.dat$cov.W
    gender<-sub.dat$sex
    
    if (dist=="normal"){
      eps<-rnorm(ll,0,eps.sd)
    }
    
    
    logS<-sub.dat$xx
    tr.z<-unique(sub.dat$true_z)
    
    #omega<-w(logS, tr.z, model)
    omega<-sub.dat$omega
    tms<-omega+eps
    
    tms.dat[[id]]<-cbind(subj,tms, omega, logS, W.cov, gender, eps,  true.z)  # true.t,eps,
    
    
  }
  
  
  ## create data.frame from list type of data
  gendat<-do.call("rbind.data.frame", tms.dat)
  
  ## Create grouped Data
  newgrdata<-groupedData(tms~logS|subj, data=gendat, order.groups=FALSE)
  
  
  
  #################################################################################################################################################
  ## Fit nonlinear mixed model using nlme() in NLME package to estimate fixed effects and random effects
  ## in longitudinal model: true data are generated by logistic model
  ## tms: longitudinal response vector for a subject i and jth visit.
  ## logistf: fitted nonlinear model.
  ## gam1, gam3, and gam4: fixed effect
  ## gam2: log transformed inflection points, which is modeled by linear relationship with
  ##         subject specific covariate W.cov, containig fixed effect beta and random effects u
  ##
  ## logS: main covariate in the logitudinal model
  ## model: tms ~logistf(theta1, theta2,  logS)
  ## fixed: two sided linear model in the form of f1~x1, where f1: names of parameters, x1: covariates in the ##linear relationship with f1
  ##       eg. theat1 ~1
  ## random: two sided formula in the form of r1~x1, where r1: names of parameters, x1 specifies the random effects model for the parameter r1
  ## groups: ~g1 or ~g1/g2../gQ, specify the partitions of the data over which the random effects vary
  ## start: list of initial estimates for the fixed effects and random effects
  ## method: "REML" or "ML", modle is fit by maximizing the restricted log liklihood or log-likelihood.
  ## verbose: TRUE means information on the evoluation of the interative algorithm is printed. Default is FALSE.
  ###################################################################################################################################################
  
  
  tms.nlme<-nlme(tms~arctanf(gam1, gam2, gam3, gam4, logS), fixed=list(gam1~1, gam2~1+W.cov, gam3~1, gam4~1),
                 random=gam2~1|subj,
                 data=newgrdata, groups=~subj, start=list(fixed=c(para1, para2, para3, para4, para5)), method="ML", verbose=FALSE)
  
  #############################################
  ### logLike, AIC #
  #############################################
  tms.logLik<-summary(tms.nlme)$logLik
  tms.AIC<-summary(tms.nlme)$AIC
  
  #############################################
  ### estimates of fixed effect: theta1, beta #
  #############################################
  
  est.gam1<-summary(tms.nlme)$tTable[,"Value"]["gam1"]
  est.gam3<-summary(tms.nlme)$tTable[,"Value"]["gam3"]
  est.gam4<-summary(tms.nlme)$tTable[,"Value"]["gam4"]
  est.beta<-summary(tms.nlme)$tTable[,"Value"]["gam2.W.cov"]
  est.beta0<-summary(tms.nlme)$tTable[,"Value"]["gam2.(Intercept)"]
  
  #####################################
  ## standard errors of fixed effects #
  #####################################
  
  
  est.str.gam1<-summary(tms.nlme)$tTable[,"Std.Error"]["gam1"]
  est.str.gam3<-summary(tms.nlme)$tTable[,"Std.Error"]["gam3"]
  est.str.gam4<-summary(tms.nlme)$tTable[,"Std.Error"]["gam4"]
  est.str.beta<-summary(tms.nlme)$tTable[,"Std.Error"]["gam2.W.cov"]
  est.str.beta0<-summary(tms.nlme)$tTable[,"Std.Error"]["gam2.(Intercept)"]
  
  
  ##########################
  ##  coverage probability #
  ##########################
  cp.fixed<-intervals(tms.nlme, level=0.95, which=c("fixed"))
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.gam1<- cp.fixed$fixed["gam1","lower"]
  cp.upper.gam1<- cp.fixed$fixed["gam1","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta0<- cp.fixed$fixed["gam2.(Intercept)","lower"]
  cp.upper.beta0<- cp.fixed$fixed["gam2.(Intercept)","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta<- cp.fixed$fixed["gam2.W.cov","lower"]
  cp.upper.beta<- cp.fixed$fixed["gam2.W.cov","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.gam3<-cp.fixed$fixed["gam3","lower"]
  cp.upper.gam3<-cp.fixed$fixed["gam3","upper"]
  
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.gam4<-cp.fixed$fixed["gam4","lower"]
  cp.upper.gam4<-cp.fixed$fixed["gam4","upper"]
  
  
  #####################
  ##  scale parameter #
  #####################
  
  ## within-individual
  sig.eps<-tms.nlme$sigma
  
  
  ###############################################################
  ## Extract Random effects with augmented data from groupedData#
  ###############################################################
  augmented.dat<-random.effects(tms.nlme, augFrame=T, data=newgrdata);
  est.rand.ef<-augmented.dat[,"gam2.(Intercept)"];
  
  
  ##################################################
  ## estimate inflection points (random effects)  ##
  ## estimate bias for inflection points          ##
  ##################################################
  
  est.logT<-est.beta0+est.beta*augmented.dat[,"W.cov"]+est.rand.ef  # estimated logT
  true.logT<-augmented.dat[,"true.z"]
  
  
  #####################################################################################################
  ### predict(): popoulation prediction (random effects=0) at polulation level 0                    ###
  ###              within group predictions (use estimated random effects) at individual level 1    ###
  #####################################################################################################
  
  
  #########################################
  # predicted total motor score           #
  #########################################
  
  
  ## set the length of time points
  
  
  
  new.pred.data<- array(0, dim=c(time.length, 5, n),
                        dimnames=list(paste("visit",1:time.length,sep=""), c("pseudo.id","pseudo.logS","pseudo.wcov", "ture.pseudo.tms", "est.pseudo.tms"), paste("ID",1:n,sep="")));
  
  
  for (id in 1:n){
    
    #id<-1; rm(id)
    group<-newgrdata[newgrdata$subj==id, ]
    
    
    pseudo.xy<-approx(group[,"logS"], group[,"omega"], n=time.length)
    pseudo.logS<-pseudo.xy$x
    pseudo.omega<-pseudo.xy$y
    
    pseudo.id<-rep(id, time.length)
    pseudo.wcov<-rep(unique(group[,"W.cov"]), time.length)
    
    if (dist=="normal"){
      pseudo.err<-rnorm(time.length,0, eps.sd)
      
    }
    
    pseudo.tms<-pseudo.omega+pseudo.err
    
    new.dat<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms)
    
    
    pred.data<-data.frame(subj= new.dat[,"pseudo.id"], logS= new.dat[,"pseudo.logS"],
                          W.cov=new.dat[ ,"pseudo.wcov"])
    
    ## predictions for tms  based on newd
    pred.traj<-predict(tms.nlme, pred.data, level=1)
    new.pred.data[,,id]<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms, pred.traj)
    
  }
  
  
  
  boot.est.logT<-array(0, dim=c(n, num.boot),
                       dimnames=list(paste("id",1:n,sep=""),paste("boot",1:num.boot,sep=""))
  )
  
  for(b in 1:num.boot){
    
    
    boot.pred.data<-vector("list", n)
    
    
    
    for(id in 1:n){
      
      ind.pred.data<-new.pred.data[,,id]
      boot.size<-dim(ind.pred.data)[[1]]
      err<-ind.pred.data[, "ture.pseudo.tms"]-ind.pred.data[, "est.pseudo.tms"]
      err.boot<-sample(err, size=boot.size, replace=TRUE)
      boot.tms<-ind.pred.data[, "est.pseudo.tms"]+err.boot
      boot.pred.data[[id]]<-cbind(ind.pred.data, boot.tms)
      
    }
    
    boot.data<-do.call("rbind.data.frame", boot.pred.data)
    
    boot.tms.nlme<-nlme(boot.tms~arctanf(gam1, gam2, gam3, gam4, pseudo.logS), fixed=list(gam1~1, gam2~1+pseudo.wcov, gam3~1, gam4~1),
                        random=gam2~1|pseudo.id,
                        data=boot.data, groups=~pseudo.id, start=list(fixed=c(para1, para2, para3, para4, para5)), method="ML", verbose=FALSE)
    
    
    boot.est.beta<-summary(boot.tms.nlme)$tTable[,"Value"]["gam2.pseudo.wcov"]
    boot.est.beta0<-summary(boot.tms.nlme)$tTable[,"Value"]["gam2.(Intercept)"]
    
    
    boot.augmented.dat<-random.effects(boot.tms.nlme, augFrame=T, data=boot.data)
    boot.est.rand.ef<-boot.augmented.dat[,"gam2.(Intercept)"]
    
    boot.est.logT[,b]<-boot.est.beta0+boot.est.beta*boot.augmented.dat[,"pseudo.wcov"]+boot.est.rand.ef  # estimated logT
    
    
  }
  
  
  
  ind.sd<-rep(100,n);
  cp.boot<-array(0, dim=c(n, 2),
                 dimnames=list(paste("id",1:n,sep=""),c("95% lower", "95% upper"))
  )
  
  
  for (id in 1:n){
    ind.boot<-boot.est.logT[id, ]
    ind.sd[id]<-sd(ind.boot)
    order.ind.boot<-sort(ind.boot)
    cp.boot[id,]<-quantile(order.ind.boot, prob=c(0.025, 0.975))
    
  }
  
  
  
  
  
  #########################################################
  # First and Second Derivative of Longitudinal Responses #
  #########################################################
  
  
  true.first.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  true.second.deriv<-array(0, dim=c(time.length,n),
                           dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  
  est.first.deriv<-array(0, dim=c(time.length,n),
                         dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  est.second.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  
  
  for (id in 1:n){
    #id<-5; rm(id)
    sub.logs<-new.pred.data[,"pseudo.logS",id]
    
    
    true.first.deriv[,id]<-logist_first_deriv_ft(true.theta1, true.logT[id], true.theta3,  sub.logs)
    true.second.deriv[,id]<-logist_second_deriv_ft(true.theta1,  true.logT[id], true.theta3,  sub.logs)
    
    
    est.first.deriv[,id]<-arctan_first_deriv_ft(est.gam1,  est.logT[id], est.gam3,  sub.logs)
    est.second.deriv[,id]<-arctan_second_deriv_ft(est.gam1,  est.logT[id], est.gam3,  sub.logs)
    
    
  }
  
  
  
  return(list(  new.pred.data= new.pred.data,
                
                est.beta=est.beta, est.beta0=est.beta0, #estimates
                
                est.str.beta=est.str.beta, est.str.beta0=est.str.beta0,#standard errors
                
                cp.lower.beta0=cp.lower.beta0, cp.upper.beta0=cp.upper.beta0, cp.lower.beta=cp.lower.beta, cp.upper.beta=cp.upper.beta, #coverage prob
                
                
                #newgrdata=newgrdata,
                sig.eps=sig.eps,
                est.rand.ef=est.rand.ef,
                est.logT=est.logT, true.logT=true.logT,
                
                ## bias of derivatives
                true.first.deriv=true.first.deriv,  true.second.deriv= true.second.deriv,  est.first.deriv= est.first.deriv, est.second.deriv=est.second.deriv,
                ## bootstrap estimation
                
                boot.est.logT=boot.est.logT,  ind.sd=ind.sd, cp.boot=cp.boot
                
  ))
  
}


#' Parametric nonlinear mixed effects model (NLME) approach: When true data are generated by the arctangent model, the parametric NLME procedure is performed under the (missepcified) logistic model.
#'
#' @param n number of sample size.
#' @param model a character string for a nonlinear model: \code{"logist"} or \code{"arctan"}.
#' @param num.boot number of bootsrap replicates.
#' @param dat a data frame of the generated data set.
#' @param time.length number of data points at which predictors are required for each individual longitudinal trajectory. This time point for graphs to be plotted.
#' @param true.gam1 a true scale parameter for \code{gam1} in the arctangent function, see \code{arctanf()}.
#' @param true.gam3 a true parameter for \code{gam3}, which determines steepness of the arctangent function, see \code{arctanf()}.
#' @param para1 an initial parameter for \code{theta1}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para2 an initial intercept parameter for the inflection point \code{theta2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para3 an initial (p-1)-length of coefficient vector of subject specific covariates for the inflection point \code{theta2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para4 an initial parameter for \code{theta3}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param eps.sd a true scale parameter of the within-subject error term in the longitudinal model.
#' @param dist a character string for the distribution of within-subject error term in the longitudinal model. Default is \code{"normal"}.
#
#'
#'
#
#'
#' @return A list of
#' \itemize{
#'        \item{est.beta}{the (p-1)-length of estimated coefficient vector of subjec-specific covariates in the log-normal model for inflection points.}
#'        \item{est.beta0}{estimated intercept of the log-normal model for inflection points.}
#'        \item{est.str.beta}{the (p-1)-length of estimated standard errors of the coefficient vector of subject-specific covariates in the log-normal model for inflection points.}
#'        \item{est.str.beta0}{estimated standard errors of the intercept of the log-normal model for inflection points.}
#'        \item{cp.lower.beta0}{estimated lower bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.upper.beta0}{estimated upper bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.lower.beta}{estimated lower bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{cp.upper.beta}{estimated upper bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{est.rand.ef}{estimated random effects in the log normal model for the inflection points.}
#'        \item{est.logT}{the n-length of the estimated inflection points vector, where each element is the individual estimated inflection point.}
#'        \item{true.logT}{the n-length of the true inflection points vector, where each element is the true individual inflection point.}
#'        \item{new.pred.data}{a time.length x 5 x n array of data set to generate boostrap estimates, which includes ID, log scaled ages, subject specfici covariates, true longitudinal trajectories and estimated longitudinal trajectories for each subject.}
#'        \item{true.first.deriv}{a time.length x n array of the first derivatives of the true longitudinal trajectories, where each column is the first derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{true.second.deriv}{a time.length x n array of the second derivatives of the true longitudinal trajectories, where each column is the second derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.first.deriv}{a time.length x n array of the estiamted first derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.second.deriv}{a time.length x n array of the estiamted second derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{boot.est.logT}{a n x num.boot array of the bootstrap estimated inflection points, where each row is a num.boot-length of boostrap estimates of the inflection point for each subject.}
#'        \item{ind.sd}{the n-length of the estimated boostrap standard deviations, where each element is the estimated standard deviation of the bootstrap estimates for each subject (each row of \code{boot.est.logT}).}
#'        \item{cp.boot}{a n x 2 array of the 95\% bootstrap confidence intervals, where each row has the lower bound and the upper bound of the 95\% confidence interval for the individual inflection point (i.e., 25th and 97.5th percentiles of the increasing ordered boostrap estimates for each row of \code{boot.est.logT}).}
#'}
#'
#' @import nlme
#' @export
#'
#' @example man/examples/missp_logist_nlme_examples.R
#'




main.logistic.missp.nlme<-function(n=80, model="arctan",  num.boot=1000, dat=outdat, time.length=20, true.gam1=2.45/pi, true.gam3=pi/1.1,  para1=3.1, para2=0.2, para3=0.2, para4=1.5, eps.sd=0.05, dist="normal"){
  
  
  ################################################################
  ## data structure constructed by each subject:  List format  ###
  ## include subject i, covariate log age,                     ###
  ##         true nonlinear function omega, error term         ###
  ##         true inflection points, true beta,                ###
  ##         true covariate W associated with inflection pts   ###
  ################################################################
  
  tms.dat<-vector("list", n)
  
  
  for(id in 1:n){
    
    sub.dat<-dat[dat$subj.id==id, ]
    ll<-dim(sub.dat)[1]
    
    subj<-sub.dat$subj.id
    true.z<-sub.dat$true_z
    W.cov<-sub.dat$cov.W
    gender<-sub.dat$sex
    
    if (dist=="normal"){
      eps<-rnorm(ll,0,eps.sd)
    }
    
    
    logS<-sub.dat$xx
    tr.z<-unique(sub.dat$true_z)
    
    #omega<-w(logS, tr.z, model)
    omega<-sub.dat$omega
    tms<-omega+eps #sub.dat$yy
    
    tms.dat[[id]]<-cbind(subj,tms, omega, logS, W.cov, gender, eps, true.z)  # true.t,eps,
    
    
  }
  
  
  ## create data.frame from list type of data
  gendat<-do.call("rbind.data.frame", tms.dat)
  
  ## Create grouped Data
  newgrdata<-groupedData(tms~logS|subj, data=gendat, order.groups=FALSE)
  
  
  
  
  #################################################################################################################################################
  ## Fit nonlinear mixed model using nlme() in NLME package to estimate fixed effects and random effects
  ## in longitudinal model: true data are generated by logistic model
  ## tms: longitudinal response vector for a subject i and jth visit.
  ## logistf: fitted nonlinear model.
  ## theta1: fixed effect
  ## theta2: log transformed inflection points, which is modeled by linear relationship with
  ##         subject specific covariate W.cov, containig fixed effect beta and random effects u
  ##
  ## logS: main covariate in the logitudinal model
  ## model: tms ~logistf(theta1, theta2,  logS)
  ## fixed: two sided linear model in the form of f1~x1, where f1: names of parameters, x1: covariates in the ##linear relationship with f1
  ##       eg. theat1 ~1
  ## random: two sided formula in the form of r1~x1, where r1: names of parameters, x1 specifies the random effects model for the parameter r1
  ## groups: ~g1 or ~g1/g2../gQ, specify the partitions of the data over which the random effects vary
  ## start: list of initial estimates for the fixed effects and random effects
  ## method: "REML" or "ML", modle is fit by maximizing the restricted log liklihood or log-likelihood.
  ## verbose: TRUE means information on the evoluation of the interative algorithm is printed. Default is FALSE.
  ###################################################################################################################################################
  
  
  tms.nlme<-nlme(tms~logistft(theta1, theta2, theta3, logS), fixed=list(theta1~1, theta2~1+W.cov, theta3~1) , random=list(theta2~1),
                 data= newgrdata, groups=~subj,  start=list(fixed=c(para1,para2,para3, para4)), method="ML", verbose=FALSE)
  
  
  #############################################
  ### estimates of fixed effect: theta1, beta #
  #############################################
  
  est.theta1<-summary(tms.nlme)$tTable[,"Value"]["theta1"]
  est.beta<-summary(tms.nlme)$tTable[,"Value"]["theta2.W.cov"]
  est.beta0<-summary(tms.nlme)$tTable[,"Value"]["theta2.(Intercept)"]
  est.theta3<-summary(tms.nlme)$tTable[,"Value"]["theta3"]
  
  #####################################
  ## standard errors of fixed effects #
  #####################################
  
  
  est.str.theta1<-summary(tms.nlme)$tTable[,"Std.Error"]["theta1"]
  est.str.beta<-summary(tms.nlme)$tTable[,"Std.Error"]["theta2.W.cov"]
  est.str.theta3<-summary(tms.nlme)$tTable[,"Std.Error"]["theta3"]
  est.str.beta0<-summary(tms.nlme)$tTable[,"Std.Error"]["theta2.(Intercept)"]
  
  
  ##########################
  ##  coverage probability #
  ##########################
  cp.fixed<-intervals(tms.nlme, level=0.95, which=c("fixed"))
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.theta1<- cp.fixed$fixed["theta1","lower"]
  cp.upper.theta1<- cp.fixed$fixed["theta1","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta0<- cp.fixed$fixed["theta2.(Intercept)","lower"]
  cp.upper.beta0<- cp.fixed$fixed["theta2.(Intercept)","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta<- cp.fixed$fixed["theta2.W.cov","lower"]
  cp.upper.beta<- cp.fixed$fixed["theta2.W.cov","upper"]
  
  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.theta3<-cp.fixed$fixed["theta3","lower"]
  cp.upper.theta3<-cp.fixed$fixed["theta3","upper"]
  
  
  #####################
  ##  scale parameter #
  #####################
  
  ## within-individual
  sig.eps<-tms.nlme$sigma
  
  
  ###############################################################
  ## Extract Random effects with augmented data from groupedData#
  ###############################################################
  augmented.dat<-random.effects(tms.nlme, augFrame=T, data=newgrdata)
  est.rand.ef<-augmented.dat[,"theta2.(Intercept)"]
  
  ##################################################
  ## estimate inflection points (random effects)  ##
  ## estimate bias for inflection points          ##
  ##################################################
  
  est.logT<-est.beta0+est.beta*augmented.dat[,"W.cov"]+est.rand.ef  # estimated logT
  true.logT<-augmented.dat[,"true.z"]
  
  
  
  #####################################################################################################
  ### predict(): popoulation prediction (random effects=0) at polulation level 0                    ###
  ###              within group predictions (use estimated random effects) at individual level 1    ###
  #####################################################################################################
  
  
  
  #########################################
  # predicted total motor score           #
  #########################################
  
  
  
  new.pred.data<- array(0, dim=c(time.length, 5, n),
                        dimnames=list(paste("visit",1:time.length,sep=""), c("pseudo.id","pseudo.logS","pseudo.wcov", "ture.pseudo.tms", "est.pseudo.tms"), paste("ID",1:n,sep="")));
  
  
  
  for (id in 1:n){
    
    group<-newgrdata[newgrdata$subj==id, ]
    
    
    pseudo.xy<-approx(group[,"logS"], group[,"omega"], n=time.length)
    pseudo.logS<-pseudo.xy$x
    pseudo.omega<-pseudo.xy$y
    
    pseudo.id<-rep(id, time.length)
    pseudo.wcov<-rep(unique(group[,"W.cov"]), time.length)
    
    if (dist=="normal"){
      pseudo.err<-rnorm(time.length,0, eps.sd)
      
    }
    
    pseudo.tms<-pseudo.omega+pseudo.err
    
    new.dat<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms)
    
    
    pred.data<-data.frame(subj= new.dat[,"pseudo.id"], logS= new.dat[,"pseudo.logS"],
                          W.cov=new.dat[ ,"pseudo.wcov"])
    
    ## predictions for tms  based on newd
    pred.traj<-predict(tms.nlme, pred.data, level=1)
    new.pred.data[,,id]<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms, pred.traj)
    
  }
  
  
  boot.est.logT<-array(0, dim=c(n, num.boot),
                       dimnames=list(paste("id",1:n,sep=""),paste("boot",1:num.boot,sep=""))
  )
  
  for(b in 1:num.boot){
    
    
    boot.pred.data<-vector("list", n)
    
    
    
    for(id in 1:n){
      
      ind.pred.data<-new.pred.data[,,id]
      boot.size<-dim(ind.pred.data)[[1]]
      err<-ind.pred.data[, "ture.pseudo.tms"]-ind.pred.data[, "est.pseudo.tms"]
      err.boot<-sample(err, size=boot.size, replace=TRUE)
      boot.tms<-ind.pred.data[, "est.pseudo.tms"]+err.boot
      boot.pred.data[[id]]<-cbind(ind.pred.data, boot.tms)
      
    }
    
    boot.data<-do.call("rbind.data.frame", boot.pred.data)
    
    
    boot.tms.nlme<-nlme(boot.tms~logistft(theta1, theta2, theta3, pseudo.logS), fixed=list(theta1~1, theta2~1+pseudo.wcov, theta3~1) , random=list(theta2~1),
                        data=boot.data, groups=~pseudo.id,  start=list(fixed=c(para1,para2,para3, para4)), method="ML", verbose=FALSE)
    
    
    boot.est.beta<-summary(boot.tms.nlme)$tTable[,"Value"]["theta2.pseudo.wcov"]
    boot.est.beta0<-summary(boot.tms.nlme)$tTable[,"Value"]["theta2.(Intercept)"]
    
    
    
    boot.augmented.dat<-random.effects(boot.tms.nlme, augFrame=T, data=boot.data)
    boot.est.rand.ef<-boot.augmented.dat[,"theta2.(Intercept)"]
    
    
    
    boot.est.logT[,b]<-boot.est.beta0+boot.est.beta*boot.augmented.dat[,"pseudo.wcov"]+boot.est.rand.ef  # estimated logT
    
    
  }
  
  
  ind.sd<-rep(100,n);
  cp.boot<-array(0, dim=c(n, 2),
                 dimnames=list(paste("id",1:n,sep=""),c("95% lower", "95% upper"))
  )
  
  
  for (id in 1:n){
    ind.boot<-boot.est.logT[id, ]
    ind.sd[id]<-sd(ind.boot)
    order.ind.boot<-sort(ind.boot)
    cp.boot[id,]<-quantile(order.ind.boot, prob=c(0.025, 0.975))
  }
  
  
  
  #########################################################
  # First and Second Derivative of Longitudinal Responses #
  #########################################################
  
  
  true.first.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  true.second.deriv<-array(0, dim=c(time.length,n),
                           dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  
  est.first.deriv<-array(0, dim=c(time.length,n),
                         dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  est.second.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  
  
  for (id in 1:n){
    
    sub.logs<-new.pred.data[,"pseudo.logS",id]
    
    
    true.first.deriv[,id]<-arctan_first_deriv_ft(true.gam1, true.logT[id], true.gam3,  sub.logs)
    true.second.deriv[,id]<-arctan_second_deriv_ft(true.gam1,  true.logT[id], true.gam3,  sub.logs)
    
    
    est.first.deriv[,id]<-logist_first_deriv_ft(est.theta1,  est.logT[id], est.theta3,  sub.logs)
    est.second.deriv[,id]<-logist_second_deriv_ft(est.theta1,  est.logT[id], est.theta3,  sub.logs)
    
    
  }
  
  
  
  return(list( new.pred.data=new.pred.data,
               est.beta=est.beta,est.beta0=est.beta0,
               
               est.str.beta=est.str.beta, est.str.beta0=est.str.beta0, #standard errors
               cp.lower.beta0=cp.lower.beta0, cp.upper.beta0=cp.upper.beta0, cp.lower.beta=cp.lower.beta,
               
               cp.upper.beta=cp.upper.beta, #coverage prob
               
               #newgrdata=newgrdata,
               sig.eps=sig.eps,
               
               est.rand.ef=est.rand.ef,
               est.logT=est.logT, true.logT=true.logT,
               ## bias of derivatives
               true.first.deriv=true.first.deriv,  true.second.deriv= true.second.deriv,  est.first.deriv= est.first.deriv, est.second.deriv=est.second.deriv,
               
               boot.est.logT=boot.est.logT,  ind.sd=ind.sd, cp.boot=cp.boot  ))
  
}

